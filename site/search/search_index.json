{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome my blog This blog exists to share my findings, tutorials and other tech-related stuff with everyone. It's also very useful for self-documentation, so hopefully sharing it with the internet would help others as well \ud83d\ude0a","title":"Home"},{"location":"#welcome-my-blog","text":"This blog exists to share my findings, tutorials and other tech-related stuff with everyone. It's also very useful for self-documentation, so hopefully sharing it with the internet would help others as well \ud83d\ude0a","title":"Welcome my blog"},{"location":"2020/","text":"TwentyTwenty is a simple PyQt app that I wrote. This app is based on the 20-20-20 rule which you can read about in the links below. Basically, the rule says that every 20 minutes, look at something 20 feet away for 20 seconds. This will help reduce: sore, tired or burning eyes blurred or double vision watery, itchy or dry eyes headaches The app runs in the background and notifies you with a Windows 10 Toast + Sound notificaiton when it\u2019s time to look away and look back. By no means should you consider this app as an alternative to a medical exam. If you feel any pain or discomfort while working on your computer, you should consult a medical professional. You can read more about the 20-20-20 rule here: https://www.juststand.org/blog/prevent-eye-strain-with-the-20-20-20-rule/ https://www.medicalnewstoday.com/articles/321536 https://www.healthline.com/health/eye-health/20-20-20-rule Download Github","title":"TwentyTwenty \u2013 My First PyQt GUI App"},{"location":"2020/#download","text":"Github","title":"Download"},{"location":"about/","text":"test","title":"About"},{"location":"about/#test","text":"","title":"test"},{"location":"automatic-dns/","text":"If you need to add multiple A records to your DNS, here\u2019s a quick way to do so. Create a CSV file, name it however you like (make sure you correct the name of the file in the script itself). Then, the first row should be filled with the words \u201cHostname\u201d and \u201cIP\u201d. You can change that as wel but once again, make sure you edit the script accordingly. Then, edit this script with your relevant information like the CSV filename, zone name, and your DC. $IPs = Import-Csv \"C:\\temp\\dnsIPs.csv\" foreach ( $item in $IPs ) { $hostname = $item .( \"Hostname\" ) $IP = $item .( \"IP\" ) Add-DnsServerResourceRecordA -Name $hostname -ZoneName \"yourcorp.com\" -IPv4Address $IP -ComputerName \"DC1\" -AsJob Get-Job | Stop-Job } That\u2019s it, now run it and watch it go \ud83d\ude42","title":"Automatically Add Multiple DNS A Records"},{"location":"client-cache/","text":"Resizing or clearing cache can be useful for many things. In this tutorial I\u2019ll show you how I do it during my Task Sequence. I personally needed it to install Visual Studio during OSD. The default size is 5120MB which is not enough in my case. Resize Cache Size $UIResourceMgr = New-Object -ComObject UIResource.UIResourceMgr $Cache = $UIResourceMgr.GetCacheInfo() $Cache.TotalSize = 25600 Clear Cache $UIResourceMgr = New-Object -ComObject UIResource.UIResourceMgr $Cache = $UIResourceMgr.GetCacheInfo() $CacheElements = $Cache.GetCacheElements() foreach ($Element in $CacheElements) { $Cache.DeleteCacheElement($Element.CacheElementID) } Save them all as .ps1 files and place in the same folder. Create a package, without a program, and don\u2019t forget to distribute it to your DP. Now you can use it as a regular PS1 script in your TS as so: For my TS, I increase the cache size, install all the software I need, clear it and then decrease it back to the default setting, since I don\u2019t want it taking too much space on the hard drive. Hope this has been helpful in some way \ud83d\ude42","title":"Resize or Clear Client Cache"},{"location":"client-cache/#resize-cache-size","text":"$UIResourceMgr = New-Object -ComObject UIResource.UIResourceMgr $Cache = $UIResourceMgr.GetCacheInfo() $Cache.TotalSize = 25600","title":"Resize Cache Size"},{"location":"client-cache/#clear-cache","text":"$UIResourceMgr = New-Object -ComObject UIResource.UIResourceMgr $Cache = $UIResourceMgr.GetCacheInfo() $CacheElements = $Cache.GetCacheElements() foreach ($Element in $CacheElements) { $Cache.DeleteCacheElement($Element.CacheElementID) } Save them all as .ps1 files and place in the same folder. Create a package, without a program, and don\u2019t forget to distribute it to your DP. Now you can use it as a regular PS1 script in your TS as so: For my TS, I increase the cache size, install all the software I need, clear it and then decrease it back to the default setting, since I don\u2019t want it taking too much space on the hard drive. Hope this has been helpful in some way \ud83d\ude42","title":"Clear Cache"},{"location":"consolidation-alert/","text":"So you might have a few alerts already set thanks to a lot of public tools out there, but if you want to get an alert about a VM that needs consolidation without installing or buying anything, you can use a simple and short PowerShell script. Connect-VIServer -Server \"your-vcenter\" $cneeded = Get-VM | Where-Object { $_ . Extensiondata . Runtime . ConsolidationNeeded } if (! $null -eq $cneeded ) { Send-MailMessage -To \"your.email\" -From \"from@email.com\" -Subject \"Consolidation Needed!\" -Body \"$cneeded\" -SmtpServer \"server-here\" -Port 25 } That\u2019s it. You can add it to a Task Scheduler and set the checks to happen whenever you like. Hope this was somewhat helpful \ud83d\ude42","title":"Send An Alert If a VM Needs Consolidation"},{"location":"csv-to-dg/","text":"If you need to add multiple users to a distribution group in Office 365, you\u2019ll find out using the GUI can take a lot of time. Luckily, it only takes a CSV file and one line of code to do this automatically. First, save a CSV file with the email addresses you need, and make sure the first line is displayname . First, test if PowerShell reads your CSV correctly as so: If your output looks like the image above, then you\u2019re good to go. The command you need to run to add the users to the distribution list is: Import-Csv $Location | foreach { Add-DistributionGroupMember -Identity \"Name of DL\" -Member $_ . displayname } For $Location , just type the path to the .csv file. It doesn\u2019t have to be a variable of course. For the -Identity , use the name of the group you want to add the users to. That\u2019s it. Hope this will be useful to someone \ud83d\ude42","title":"Add Users From a CSV to a Distribution Group with PowerShell"},{"location":"direnv/","text":"Direnv If you\u2019re bouncing between multiple AWS accounts or credentials in your CLI, this tool might be a huge quality of life perk for you. Basically, direnv can load and unload environment variables depending on the current directory you\u2019re in. In this post I\u2019ll show how to use it to switch between AWS credentials. Let\u2019s start with a real world example right of the bat: ~/playground master* \u276f ls -l total 20 drwxr-xr-x 2 dbei dbei 4096 Apr 21 09 :37 project1 drwxr-xr-x 2 dbei dbei 4096 Apr 21 09 :37 project2 ~/playground master* Project1 will use AWS Account #1 Project2 will use AWS Account #2 Let\u2019s start with Project1: Setup direnv . cd into your desired directory. In my case it would be project1 . Create .envrc : vi .envrc Add your AWS credentials which you can generate in IAM: export AWS_ACCESS_KEY_ID=AKIAZXIDSFDSNTLBJWC export AWS_DEFAULT_REGION=eu-west-1 export AWS_SECRET_ACCESS_KEY=KJuja33rTxIlK/wee/DsdrdhjKKg/HDrmtreDJ cd in and out of that directory. You should see an error: Error direnv: error /playground/project1/.envrc is blocked. Run direnv allow to approve its content Type direnv allow and you should be good: ~/playground/project1 master* \u276f direnv allow direnv: loading ~/playground/project1/.envrc direnv: export ~AWS_DEFAULT_REGION You can test that it works with any AWS CLI command. For example: ~/playground/project1 master* \u276f aws s3 ls 2022 -03-22 16 :35:07 daniel-awesome-bucket 2022 -04-21 09 :18:52 do -not-delete-gatedgarden-audit-384466123559 ~/playground/project1 master* \u276f Repeat the same process for Project2 and use different credentials. After that, you should be set. From here you can move between folders, which will automatically move between your AWS credentials and accounts! Tip Don\u2019t forget to add .envrc to your .gitignore !","title":"Switch Between AWS Credentials With Direnv"},{"location":"direnv/#direnv","text":"If you\u2019re bouncing between multiple AWS accounts or credentials in your CLI, this tool might be a huge quality of life perk for you. Basically, direnv can load and unload environment variables depending on the current directory you\u2019re in. In this post I\u2019ll show how to use it to switch between AWS credentials. Let\u2019s start with a real world example right of the bat: ~/playground master* \u276f ls -l total 20 drwxr-xr-x 2 dbei dbei 4096 Apr 21 09 :37 project1 drwxr-xr-x 2 dbei dbei 4096 Apr 21 09 :37 project2 ~/playground master* Project1 will use AWS Account #1 Project2 will use AWS Account #2 Let\u2019s start with Project1: Setup direnv . cd into your desired directory. In my case it would be project1 . Create .envrc : vi .envrc Add your AWS credentials which you can generate in IAM: export AWS_ACCESS_KEY_ID=AKIAZXIDSFDSNTLBJWC export AWS_DEFAULT_REGION=eu-west-1 export AWS_SECRET_ACCESS_KEY=KJuja33rTxIlK/wee/DsdrdhjKKg/HDrmtreDJ cd in and out of that directory. You should see an error: Error direnv: error /playground/project1/.envrc is blocked. Run direnv allow to approve its content Type direnv allow and you should be good: ~/playground/project1 master* \u276f direnv allow direnv: loading ~/playground/project1/.envrc direnv: export ~AWS_DEFAULT_REGION You can test that it works with any AWS CLI command. For example: ~/playground/project1 master* \u276f aws s3 ls 2022 -03-22 16 :35:07 daniel-awesome-bucket 2022 -04-21 09 :18:52 do -not-delete-gatedgarden-audit-384466123559 ~/playground/project1 master* \u276f Repeat the same process for Project2 and use different credentials. After that, you should be set. From here you can move between folders, which will automatically move between your AWS credentials and accounts! Tip Don\u2019t forget to add .envrc to your .gitignore !","title":"Direnv"},{"location":"media-server/","text":"Intro Hello everyone. In this tutorial I wanted to share my setup for my home automation. It took me a while to get everything going and working properly, but I'm currently at a point where everything is working and I'm happy with the result, so I wanted to share it with you \ud83d\ude0a My setup HP EliteBook G2 as my home server (running Ubuntu) Asustor AS1004t v2 NAS for my storage (RAID5, 4x1TB HDDs) My ISP's router. Goal Automatically download my media Automatically rename the media and organize in folders Run everything from Dockers Copyright Notice I will be using usenet and torrents to download shows, movies and books. I am not responsible for whatever you'll do with this setup. If piracy is illegal in your country and you're afraid of actions that can be taken by your ISP, I suggest you won't go through with it. With that being said, you can also mask your traffic behind a VPN of your choice, which I won't be covering in this tutorial. Apps we'll use Radarr - managing movies Sonarr - managing tv shows Plex - my media player of choice. A lot of people would also recommend Jellyfin which is open-source and great as well \ud83d\ude0a SABnzbd - my binary newsgroup downloader of choice. qBitTorrent - torrent downloader of choice. How-To Docker & Docker-Compose I will be sharing my docker-compose file which will include all of the relevant apps for this project. You will need to install both Docker and Docker Compose on your server of choice. Installing Docker and Docker-Compose is as simple as it gets: - Docker - Docker-Compose NAS Setup and paths Create a volume in your NAS. In my case, I created a RAID5 volume with 4 disks Info The mount command can vary between systems. Don't forget to change the server's IP to yours. If you didn't name your folder data , change that to whatever you named your folder. Go to your server and mount the network path. run mount -o v3 192.168.1.14:/volume1/data /mnt/data edit /etc/fstab to have the drive mount itself on boot: 192.168.1.14:/volume1/data /mnt/data nfs defaults 0 0 run mount --all You should now see your drive mounted: \u276f df -h Filesystem Size Used Avail Use% Mounted on /dev/sda5 234G 23G 200G 11 % / 192 .168.1.14:/volume1/data 2 .7T 1 .6T 1 .2T 57 % /mnt/data ... Tip From here we will be doing exactly as stated under TRaSH guides . Please more about it if you wish to understand why. Open your mount, and create folders using the following structure: data \u251c\u2500\u2500 torrents \u2502 \u251c\u2500\u2500 movies \u2502 \u2514\u2500\u2500 tv \u251c\u2500\u2500 usenet \u2502 \u251c\u2500\u2500 movies \u2502 \u2514\u2500\u2500 tv \u2514\u2500\u2500 media \u251c\u2500\u2500 movies \u2514\u2500\u2500 tv In the ends, once you go into /mnt/data , the folder should look like this: beinish in Media-Server in /mnt/data \u276f ls -l total 16 drwxrwxr-x 5 beinish beinish 4096 Oct 4 14 :04 media drwxrwxr-x 5 beinish beinish 4096 Oct 4 14 :02 torrents drwxrwxr-x 6 beinish beinish 4096 Oct 19 15 :36 usenet Portainer I chose Portainer to avoid managing my Docker containers via CLI. Installing Portainer is very simple, you can choose the method of installation from their website . After installing it, make sure it's running: root@server:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de5b28eb2fa9 portainer/portainer-ce:2.9.3 \"/portainer\" 2 weeks ago Up 9 days 0 .0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0 .0.0.0:9443->9443/tcp, :::9443->9443/tcp portainer Compose-File The following docker-compose file is configured exactly as it should, we will make some changes after running it: version : \"3.2\" services : radarr : container_name : radarr image : cr.hotio.dev/hotio/radarr:latest restart : unless-stopped logging : driver : json-file ports : - 7878:7878 hostname : radarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/radarr:/config - /mnt/data:/data sonarr : container_name : sonarr image : cr.hotio.dev/hotio/sonarr:latest restart : unless-stopped logging : driver : json-file ports : - 8989:8989 hostname : sonarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/sonarr:/config - /mnt/data:/data bazarr : container_name : bazarr image : cr.hotio.dev/hotio/bazarr:latest restart : unless-stopped logging : driver : json-file ports : - 6767:6767 hostname : bazarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/bazarr:/config - /mnt/data/media:/data/media qbittorrent : container_name : qbittorrent image : cr.hotio.dev/hotio/qbittorrent ports : - \"8080:8080\" hostname : qbittorrent environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem volumes : - /docker/appdata/qbittorrent:/config - /mnt/data/torrents:/data/torrents plex : container_name : plex image : cr.hotio.dev/hotio/plex # ports: # - \"32400:32400\" hostname : plex network_mode : host environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem - PLEX_CLAIM - ADVERTISE_IP - ALLOWED_NETWORKS - PLEX_PASS=no volumes : - /docker/appdata/plex:/config - /docker/appdata/plex/transcode:/transcode - /mnt/data/media:/data/media sabnzbd : image : lscr.io/linuxserver/sabnzbd:latest container_name : sabnzbd environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /docker/appdata:/config - /mnt/data/usenet:/data/usenet ports : - 8081:8081 hostname : sabnzbd restart : unless-stopped jackett : container_name : jackett image : cr.hotio.dev/hotio/jackett ports : - \"9117:9117\" hostname : jackett environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem volumes : - /docker/appdata/jackett:/config overseerr : image : sctx/overseerr:latest container_name : overseerr environment : - LOG_LEVEL=debug ports : - 5055:5055 hostname : overseerr volumes : - /docker/appdata/overseerr:/app/config restart : unless-stopped","title":"Media Server Automation"},{"location":"media-server/#intro","text":"Hello everyone. In this tutorial I wanted to share my setup for my home automation. It took me a while to get everything going and working properly, but I'm currently at a point where everything is working and I'm happy with the result, so I wanted to share it with you \ud83d\ude0a","title":"Intro"},{"location":"media-server/#my-setup","text":"HP EliteBook G2 as my home server (running Ubuntu) Asustor AS1004t v2 NAS for my storage (RAID5, 4x1TB HDDs) My ISP's router.","title":"My setup"},{"location":"media-server/#goal","text":"Automatically download my media Automatically rename the media and organize in folders Run everything from Dockers","title":"Goal"},{"location":"media-server/#copyright-notice","text":"I will be using usenet and torrents to download shows, movies and books. I am not responsible for whatever you'll do with this setup. If piracy is illegal in your country and you're afraid of actions that can be taken by your ISP, I suggest you won't go through with it. With that being said, you can also mask your traffic behind a VPN of your choice, which I won't be covering in this tutorial.","title":"Copyright Notice"},{"location":"media-server/#apps-well-use","text":"Radarr - managing movies Sonarr - managing tv shows Plex - my media player of choice. A lot of people would also recommend Jellyfin which is open-source and great as well \ud83d\ude0a SABnzbd - my binary newsgroup downloader of choice. qBitTorrent - torrent downloader of choice.","title":"Apps we'll use"},{"location":"media-server/#how-to","text":"","title":"How-To"},{"location":"media-server/#docker-docker-compose","text":"I will be sharing my docker-compose file which will include all of the relevant apps for this project. You will need to install both Docker and Docker Compose on your server of choice. Installing Docker and Docker-Compose is as simple as it gets: - Docker - Docker-Compose","title":"Docker &amp; Docker-Compose"},{"location":"media-server/#nas-setup-and-paths","text":"Create a volume in your NAS. In my case, I created a RAID5 volume with 4 disks Info The mount command can vary between systems. Don't forget to change the server's IP to yours. If you didn't name your folder data , change that to whatever you named your folder. Go to your server and mount the network path. run mount -o v3 192.168.1.14:/volume1/data /mnt/data edit /etc/fstab to have the drive mount itself on boot: 192.168.1.14:/volume1/data /mnt/data nfs defaults 0 0 run mount --all You should now see your drive mounted: \u276f df -h Filesystem Size Used Avail Use% Mounted on /dev/sda5 234G 23G 200G 11 % / 192 .168.1.14:/volume1/data 2 .7T 1 .6T 1 .2T 57 % /mnt/data ... Tip From here we will be doing exactly as stated under TRaSH guides . Please more about it if you wish to understand why. Open your mount, and create folders using the following structure: data \u251c\u2500\u2500 torrents \u2502 \u251c\u2500\u2500 movies \u2502 \u2514\u2500\u2500 tv \u251c\u2500\u2500 usenet \u2502 \u251c\u2500\u2500 movies \u2502 \u2514\u2500\u2500 tv \u2514\u2500\u2500 media \u251c\u2500\u2500 movies \u2514\u2500\u2500 tv In the ends, once you go into /mnt/data , the folder should look like this: beinish in Media-Server in /mnt/data \u276f ls -l total 16 drwxrwxr-x 5 beinish beinish 4096 Oct 4 14 :04 media drwxrwxr-x 5 beinish beinish 4096 Oct 4 14 :02 torrents drwxrwxr-x 6 beinish beinish 4096 Oct 19 15 :36 usenet","title":"NAS Setup and paths"},{"location":"media-server/#portainer","text":"I chose Portainer to avoid managing my Docker containers via CLI. Installing Portainer is very simple, you can choose the method of installation from their website . After installing it, make sure it's running: root@server:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de5b28eb2fa9 portainer/portainer-ce:2.9.3 \"/portainer\" 2 weeks ago Up 9 days 0 .0.0.0:8000->8000/tcp, :::8000->8000/tcp, 0 .0.0.0:9443->9443/tcp, :::9443->9443/tcp portainer","title":"Portainer"},{"location":"media-server/#compose-file","text":"The following docker-compose file is configured exactly as it should, we will make some changes after running it: version : \"3.2\" services : radarr : container_name : radarr image : cr.hotio.dev/hotio/radarr:latest restart : unless-stopped logging : driver : json-file ports : - 7878:7878 hostname : radarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/radarr:/config - /mnt/data:/data sonarr : container_name : sonarr image : cr.hotio.dev/hotio/sonarr:latest restart : unless-stopped logging : driver : json-file ports : - 8989:8989 hostname : sonarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/sonarr:/config - /mnt/data:/data bazarr : container_name : bazarr image : cr.hotio.dev/hotio/bazarr:latest restart : unless-stopped logging : driver : json-file ports : - 6767:6767 hostname : bazarr environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /etc/localtime:/etc/localtime:ro - /docker/appdata/bazarr:/config - /mnt/data/media:/data/media qbittorrent : container_name : qbittorrent image : cr.hotio.dev/hotio/qbittorrent ports : - \"8080:8080\" hostname : qbittorrent environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem volumes : - /docker/appdata/qbittorrent:/config - /mnt/data/torrents:/data/torrents plex : container_name : plex image : cr.hotio.dev/hotio/plex # ports: # - \"32400:32400\" hostname : plex network_mode : host environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem - PLEX_CLAIM - ADVERTISE_IP - ALLOWED_NETWORKS - PLEX_PASS=no volumes : - /docker/appdata/plex:/config - /docker/appdata/plex/transcode:/transcode - /mnt/data/media:/data/media sabnzbd : image : lscr.io/linuxserver/sabnzbd:latest container_name : sabnzbd environment : - PUID=1000 - PGID=1000 - TZ=Asia/Jerusalem volumes : - /docker/appdata:/config - /mnt/data/usenet:/data/usenet ports : - 8081:8081 hostname : sabnzbd restart : unless-stopped jackett : container_name : jackett image : cr.hotio.dev/hotio/jackett ports : - \"9117:9117\" hostname : jackett environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Asia/Jerusalem volumes : - /docker/appdata/jackett:/config overseerr : image : sctx/overseerr:latest container_name : overseerr environment : - LOG_LEVEL=debug ports : - 5055:5055 hostname : overseerr volumes : - /docker/appdata/overseerr:/app/config restart : unless-stopped","title":"Compose-File"},{"location":"pandas-delta/","text":"I automated a silly task as a beginner\u2019s project in Python. It was a nice learning experience as I don\u2019t do this quite often. So we have a list of upcoming new employees in an Excel file. It has their name and start date. There are a few people in our office that need a reminder that new people are joining, so this script sends them that email with all the details. Generally, if there\u2019s a new employee on that list that starts in less than 10 days, it adds him to a table and sends that in an email. I run this script in a cron-job once a week at the same hour. import pandas as pd import datetime as dt import smtplib , ssl from email.mime.multipart import MIMEMultipart def sendEmail (): sender_email = \"\" receiver_email = \"\" message = MIMEMultipart ( \"alternative\" ) message [ \"Subject\" ] = \"New Employees Reminder\" message [ \"From\" ] = sender_email message [ \"To\" ] = receiver_email # Create the plain-text and HTML version of your message text = \"\"\" Test \"\"\" #Open the HTML file we created because we don't want to output raw HTML code. This adds the new employees table to the email. with open ( 'employees.html' ) as fp : html = fp . read () part1 = MIMEText ( text , \"plain\" ) part2 = MIMEText ( html , \"html\" ) message . attach ( part1 ) message . attach ( part2 ) try : smtpObj = smtplib . SMTP ( 'server' ) smtpObj . sendmail ( sender_email , receiver_email , message . as_string ()) print ( \"Successfully sent email\" ) except SMTPException : print ( \"Error: unable to send email\" ) #Read the Excel file, read the specific sheet we need and take just the column we're interested in: Start Date xls = pd . ExcelFile ( r 'testfile.xlsx' ) df = pd . read_excel ( xls , 'New Employment' ) df [ 'Start Date' ] = pd . to_datetime ( df [ 'Start Date' ]) today = pd . Timestamp . today () #Calculate how many days are left til the employee starts working using Pandas. It's a delta from today's date and the date in the Excel file. df [ 'Days Until Start' ] = (( df [ 'Start Date' ] - today ) . dt . days ) df [ 'Days Until Start' ] = df [ 'Days Until Start' ] . astype ( int ) delta_df = df [[ 'Name' , 'Days Until Start' ]] close_delta = delta_df [ delta_df [ 'Days Until Start' ] . between ( 0 , 10 )] #Make sure the employees delta is no bigger than 0 because that means he already started working and smaller than 10 (reasonable time to prepare for a new employee) close_delta . to_html ( 'employees.html' ) #Output the data into a table inside the HTML file which we will use for the \"Send Email\" function. if len ( close_delta ) > 0 : #Check if there are any employees queued up, so it won't send an email with an empty list in case there are no new employees soon. sendEmail () The output looks something like this: Hope this will be helpful to someone \ud83d\ude0a","title":"Pandas \u2013 Get delta of two dates"},{"location":"sccm-drivers/","text":"There is the traditional way of importing drivers where you download driver packs, import the drivers and then create a package for them. I decided to go with a less known, but better way of applying drivers to your OSD. First, we\u2019ll download the drivers we want to apply. For this example, I will use drivers for HP 840 G3 . Drivers for HP Each vendor has driver packs for his computers. In my case, this is HP\u2019s website . I\u2019ll find the latest drivers and download them. I\u2019ll download and transfer the file to a folder I created inside the SCCM server. Open the .exe file and extract the files to our folder. Now, go to Software Library > Packages and create a new regular package. Now that the package is created, distribute it to our DP Now that we have the package, we\u2019ll go to our TS and edit it. We\u2019ll go to the drivers section and create a new \u201ccommand line\u201d step. We\u2019ll add the following command as the command line: DISM.exe /Image:%OSDisk%\\ /Add-Driver /Driver:.\\ /Recurse And choose the package we created as package: In options, we\u2019ll create a new Query WMI and use the following statement: SELECT * FROM Win32_ComputerSystem WHERE Model = \"HP EliteBook 840 G3\" Testing this we can see it is valid: Set up Success codes as this: 2 50 You can see it works during deployment: That\u2019s it. To add new packages, for different computers, we\u2019ll do everything the same except we need to change the Query to match the model number. Information To get a model number of a computer, use the following command in CMD: WMIC CSPRODUCT GET NAME Always use the full name.","title":"Apply drivers in SCCM \u2013 The Easy Way"},{"location":"sccm-osd/","text":"If you\u2019re looking to organize new computers that you deploy, then this might be helpful. First, save the following code as AddMeToCollection.vbs '========================================================================== ' ' NAME: AddMeToCollection.vbs ' ' AUTHOR: Vinay, Microsoft ' DATE : 8/7/2010 ' ' COMMENT: Script to add Unknown Computer to a specified collection during OSD ' USAGE: cscript AddMeToCollection.vbs %_SMSTSClientIdentity% '========================================================================== On Error Resume Next Dim arrArguments Set arrArguments = WScript.Arguments If arrArguments.Count <> 3 Then WScript.Echo \"Usage: cscript AddMeToCollection.vbs %_SMSTSClientIdentity%\" WScript.Echo \" and needs to be specified, but last parameter needs to be used as is.\" WScript.Quit End If Dim strServer, strCollID, strProvNamespace Dim strComputerName, strGUID, strResourceID Dim strUser, strPassword strResourceID = 0 strServer = arrArguments(0) strCollID = arrArguments(1) strGUID = arrArguments(2) WScript.Echo \"\" WScript.Echo \"===================================\" WScript.Echo \" ADDING COMPUTER TO COLLECTION\" WScript.Echo \"===================================\" WScript.Echo \"Site Server specified: \" & strServer WScript.Echo \"Collection ID specified: \" & strCollID WScript.Echo \"SMS Client \" & strGUID 'Get the computer name Set oNet = CreateObject(\"WScript.Network\") strComputerName = oNet.ComputerName WScript.Echo \"Computer Name: \" & strComputerName Set oNet = Nothing 'Connect to root/sms namespace on SMS Site Server to find the Provider Namespace Set objLocator = CreateObject(\"WbemScripting.SWbemLocator\") Set oWbem = objLocator.ConnectServer(strServer, \"root/sms\") If Err.number <> 0 Then WScript.Echo \"Error connecting to root\\sms namespace to find Provider Location. Exiting!\" WScript.Echo \"Error = \" & Err.number & \" - \" & Err.Description WScript.Quit End If Set colNameSpace = oWbem.ExecQuery(\"SELECT * FROM SMS_ProviderLocation\") For Each item in colNameSpace WScript.Echo \"SMS Provider Namespace = \" & item.NamespacePath strProvNamespace = item.NamespacePath Next 'Connect to the Provider Namespace Set oWbem = objLocator.ConnectServer(strServer, strProvNamespace) If Err.number <> 0 Then WScript.Echo \"Error connecting to SMS Provider namespace. Exiting!\" WScript.Echo \"Error = \" & Err.number & \" - \" & Err.Description WScript.Quit Else WScript.Echo \"Successfully Connected to the SMS Provider Namespace\" End If 'Find out the Resource ID of the computer by querying SMS_R_System Class against the SMS GUID Set colResources = oWbem.ExecQuery(\"SELECT ResourceID FROM SMS_R_System WHERE SMSUniqueIdentifier = '\" & strGUID & \"'\") For Each oResource In colResources strResourceID = oResource.ResourceID WScript.Echo \"Resource ID = \" & strResourceID Next 'If Resource ID was not found, exit gracefully If strResourceID = 0 Then WScript.Echo \"Could not find the Resource ID for the computer. Exiting!\" WScript.Quit End If 'Verify if the specified collection exists Set oCollection = oWbem.Get(\"SMS_Collection.CollectionID=\" & \"\"\"\" & strCollID & \"\"\"\") If oCollection.Name = \"\" Then WScript.Echo \"Specified Collection (\" & strCollID & \") was Not Found. Exiting!\" WScript.Quit End If 'Create a Direct Membership rule Set oDirectRule = oWbem.Get(\"SMS_CollectionRuleDirect\").SpawnInstance_ () oDirectRule.ResourceClassName = \"SMS_R_System\" oDirectRule.ResourceID = strResourceID oDirectRule.RuleName = strComputerName & \" - SMSTS\" 'Add the Direct Membership Rule to the specified collection oCollection.AddMembershipRule oDirectRule If Err.Number <> 0 Then WScript.Echo \"Could not add the computer to the specified collection. Exiting!\" WScript.Echo \"Error = \" & Err.number & \" - \" & Err.Description WScript.Quit Else WScript.Echo strComputerName & \" successfully added To \" & strCollID End If WScript.Echo \"===================================\" WScript.Echo \"\" Set objLocator = Nothing Set oWbem = Nothing Set oCollection = Nothing Set oDirectRule = Nothing 'End Script Move it to a folder in your SCCM server and create a new package. Now go to your Task Sequence and add a command line Add the following command: cscript AddMeToCollection.vbs sccm.server.com XX100028 %_SMSTSClientIdentity% Where sccm.server.com is, replace it with your SCCM server. For XX1000E1 , replace it with the collection\u2019s ID. I personally had to use a privileged account for it to work. I apply this after the client is installed, and from my testing, it failed without admin rights. As always, your mileage may vary. How it can be used This script can be super useful in environments where you deploy all kinds of image versions for different departments. For example, I use TsGui and created an XML GUI to choose which customization to apply to the image using variables. This script helped me add the device I\u2019m imaging to the correct collection because I configure each department separately, as can be seen here: Note In my environment, the new device appears as \u201cUnknown\u201d fora while (15-30 minutes) but eventually gets the correct hostname. Hope this has been useful to you \ud83d\ude42","title":"Add a device to a collection during OSD"},{"location":"sccm-osd/#how-it-can-be-used","text":"This script can be super useful in environments where you deploy all kinds of image versions for different departments. For example, I use TsGui and created an XML GUI to choose which customization to apply to the image using variables. This script helped me add the device I\u2019m imaging to the correct collection because I configure each department separately, as can be seen here: Note In my environment, the new device appears as \u201cUnknown\u201d fora while (15-30 minutes) but eventually gets the correct hostname. Hope this has been useful to you \ud83d\ude42","title":"How it can be used"},{"location":"sccm-power-plan/","text":"In this guide I\u2019ll show you how to set the Power Plan of Windows to High Performance during the OSD. This is good for one main reason: Speed up the deployment time. It seems that after some tests, this can speed up the OSD by 20-50% (depending on the environment and the deployment). First, create a new \u201cRun Command Line\u201d step. In the command line add this: PowerCfg.exe /s 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c Note Every power plan has it\u2019s own GUID. If you wish to set it back to something else, simply choose your GUID and implement it later in the TS. More information is here . Mode Description GUID Power Saver Delivers reduced performance which may increase power savings. a1841308-3541-4fab-bc81-f71556f20b4a Balanced Automatically balances performance and power consumption according to demand. 381b4222-f694-41f0-9685-ff5bb260df2e High Performance Delivers maximum performance at the expense of higher power consumption. 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c Under the Options tab, create a TS Variable like this: Now, I also added this power plan to take affect during WinPE as well like this: X:\\Windows\\System32\\PowerCfg.exe /s 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c For testing purposes, I created a TS for this alone: Deploying it to my machine worked great: That's it, hope it helps someone \ud83d\ude0a","title":"Set a Power Plan in SCCM"},{"location":"sccm-vs/","text":"In this tutorial, we\u2019ll go through deploying VS17 in SCCM. Download the installer and save it under a folder of your choice. For this tutorial I\u2019ll use C:\\VS17 Open CMD and use -layout command of your choice. My command: vs_enterprise.exe --layout c:\\vslayout --add Microsoft.VisualStudio.Workload.ManagedDesktop --add Microsoft.VisualStudio.Workload.NetWeb --add Component.GitHub.VisualStudio --includeOptional --lang en-US More VS Components Add components as you please, the list can be found here . Note the full featured installation requires about 40GB of free space. It will now download all the necessary files to the folder. Tip Grab some coffee, it can take a while Copy all the files to your SCCM server and let\u2019s create a new App to deploy. Point to the offline files we downloaded earlier as the \u201ccontent location\u201d. For the installation command we\u2019ll use the same command we used for the \u2013layout command earlier when we downloaded the files offline. Just add your desired switches to the installation. Note Add \u2013productKey to use your license More information on switches . Installation Program: vs_enterprise.exe --add Microsoft.VisualStudio.Workload.ManagedDesktop --add Microsoft.VisualStudio.Workload.NetWeb --add Component.GitHub.VisualStudio --includeOptional --quiet --wait --norestart --productKey XXXXXXXXXXXXXXXXXXXX Tip Uninstall: vs_enterprise.exe --uninstall I personally only use file detection as the discovery method. Use the path to the default installation folder and search for devenv.exe Path: %ProgramFiles(x86)%\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE That\u2019s it. Deploy and test to see if it works. Tip Don\u2019t forget to to distribute to your DP. You can improve this deployment by adding another detection method for the VS version you\u2019re installing. You can also add dependencies for this to be installed if you\u2019re deploying outside of your task sequence. Good luck \ud83d\ude42","title":"Deploy Visual Studio 2017 with SCCM"},{"location":"shutdown-delete/","text":"This is a simple script to shutdown and delete multiple VMs at once in VMware. Make sure you have a list of VMs in a text file. It\u2019s simple to export a list of VMs in a certain folder in your vcenter, but just as an example, it should look like this: Then, here\u2019s the script, run it: $vcenter = Read-Host ( \"Enter VCenter IP\" ) $VMs = ( Get-Content C :\\ temp \\ vmlist . txt ) $vmObj = Get-vm $vms Connect-VIServer $vcenter foreach ( $active in $vmObj ){ if ( $active . PowerState -eq \"PoweredOn\" ){ Stop-VM -VM $active -Confirm : $false -RunAsync | Out-Null } } Start-Sleep -Seconds 7 foreach ( $delete in $vmObj ){ Remove-VM -VM $delete -DeleteFromDisk -Confirm : $false -RunAsync | Out-Null } You can separate this script to just shutdown or just delete from disk. Use it whatever way you please. It\u2019s a simple script, but as always, if I used it at least a few times, it worth sharing \ud83d\ude42","title":"Shutdown and Delete Multiple VMs Automatically"},{"location":"ssm-patch-group/","text":"Recently I needed to add multiple instances to a Patch Group. - This is done by adding a tag to each instances where the key is Patch Group and the value is a name of your choice. If you use AWS\u2019s SSM service, you know that through the Console you are only able to add one tag at a time. This short script will show you how to tag multiple instances at once. Before that, we need to differentiate between EC2 instances and SSM Managed Instances. EC2 Instance \u2013 a regular EC2 instance. Represented by an instance ID that starts with i- Managed Instance \u2013 An on-premise or non EC2 managed instance that you can manage in SSM. Represented by and instance ID that starts with mi- Before you start, make sure you have 2 things: Boto3 installed The appropriate IAM permissions (use aws configure to set your test environment) I want to add all of my Amazon Linux 2 machines to their own Patch Group. In my example, I only add the tags to EC2 instances, but the same logic applies to managed instances as well. import boto3 ssm_client = boto3 . client ( 'ssm' ) ec2_client = boto3 . client ( 'ec2' ) tags = { 'Key' : 'Patch Group' , 'Value' : 'AL2-Test' } all_instances = [] for instance in ssm_client . describe_instance_information ()[ 'InstanceInformationList' ]: if instance [ 'PlatformName' ] == 'Amazon Linux' and instance [ 'PlatformVersion' ] == '2' : all_instances . append ( instance [ 'InstanceId' ]) for instance in all_instances : ec2_client . create_tags ( # DryRun=True, Resources = [ instance ], Tags = [ tags ] ) You can choose whatever tags you want for your key/value tags = { 'Key' : 'Patch Group' , 'Value' : 'AL2-Test' } You can also use more tags. The first loop iterates over all of the instances in SSM, and if the instance\u2019s OS is Amazon Linux 2, it gets added to a list of instances. The second loop goes over the list of instances we just filled and simply creates the tags we configured. As you can see, by running we get our desired result: The same logic can be applied to SSM Managed Instances. Instead of using the EC2 boto3 client, we can utilize the same SSM client we already have and use the add_tags_to_resource function: response = client . add_tags_to_resource ( ResourceType = 'Document' | 'ManagedInstance' | 'MaintenanceWindow' | 'Parameter' | 'PatchBaseline' | 'OpsItem' | 'OpsMetadata' , ResourceId = 'string' , Tags = [ { 'Key' : 'string' , 'Value' : 'string' }, ] ) That\u2019s it. Hope it has been helpful to someone \ud83d\ude0a","title":"Add Multiple Instances To a Patch Group in SSM"},{"location":"static-ip/","text":"This script reaches out to each computer you have in your .csv and sets a static IP for it. Will you ever use it? Probably not because luckily, DHCP is a thing. I personally found it useful for a few very specific scenarios so here it is anyway \ud83d\ude42 First, create a .csv file that looks like this: Note you can use different names for the headers, just make sure to change them in the script as well Make sure you use \u201cName\u201d and \u201cNew IP\u201d as seen in the pictures. Info Don't forget to change the $GW variable to your GW's IP. $vcenter = Read-Host ( \"Enter VCenter:\" ) Connect-VIServer $vcenter $IPs = Import-Csv \"C:\\temp\\newIPs.csv\" $GW = \"GW\" # Change this to Gateway of your choosing! foreach ( $item in $IPs ) { $hostname = $item .( \"Name\" ) $New_IP = $item .( \"New IP\" ) Invoke-Command -ComputerName $hostname -ScriptBlock { New-NetIPAddress -IPAddress $using : New_IP -DefaultGateway $using : GW -PrefixLength 24 -InterfaceIndex ( Get-NetAdapter ). InterfaceIndex -AsJob } Get-Job | Stop-Job } The script will set the static IPs of your choosing to your VMs. Enjoy \ud83d\ude0a Notes You will need to enable WinRM Don't forget to change the path of the script","title":"Automatically set a static IP for multiple hosts"},{"location":"vm-cloner/","text":"VM Cloner is just a hobby project I wrote to allow myself to clone VMs in our vSphere environment. This script is pretty customized to my needs. Since every work environment is different, I'd make sure to read everything below and figure out if it suits you. This is my very first GUI project for Powershell. I can tell in advance that it's not perfect, but it's working. Any feedback is always welcome. Use this with caution, as always, your millage may vary. Github Link","title":"VM Cloner"}]}